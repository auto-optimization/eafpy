# Reading
### PyMoo
PyMoo uses [matplotlib for its plotting](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9078759). It uses sphinx for documentation, their documentation looks very aesthetic, I can go to there for inspiration.

In pymoo, they embed jupyter notebooks in their Sphinx documentation -> Learn how to do this. They also have some resources for learning multi-objective optimisation

#### Performance indictors
[pymoo - indicators](https://pymoo.org/misc/indicators.html)
Indicators take all the datapoints of a Known problems pareto front and compare them to one algorithms results? Resulting in one scaler. This is true for `Generational distance` related indicators.

For a `hypervolume`, only a single reference point needs to be provided.


### MOO 
Pareto front -> A set of solutions that are not diminated eg. They don't have a better solution in all objectives

Decision space -> Parameters that we can chance eg. Parameters
Objective space -> Features that we want eg. Accuracy, failure rate etc.

Genetic algorithm -> Can use a parato front when deciding which parts of population to carry forward. Pareto front is also the final output of the genetic algorithm.

MOO is generally agnostic of scales for every objective.
#### When to use?
MOO can be used when there is a very large, intractable decision space.
It can be used when it is required to explore the whole objective space

### EAF 
[Chapter 9
Exploratory Analysis of Stochastic Local Search
Algorithms in Biobjective Optimization](https://link.springer.com/chapter/10.1007/978-3-642-02538-9_9) 
The attainment function can be used to evaluate the pareto front over different runs of a MOO algorithm, or perhaps between different algorithms?

Attainment surfaces:
My understanding is that attainment surfaces can map the variation in pareto front from different runs of a stachastic algorithm, for example showing the lower, middle and upper quartile of these fronts. 

"The EAF of an algorithm estimates the probability of attaining
each point in the objective space"
"If the difference of the estimated probability values
of two SLS algorithms at a certain point is large, this indicates better performance of
one algorithm over another at that point"

[The Attainment-Function Approach to
Stochastic Multiobjective Optimiser
Assessment and Comparison](https://www.imada.sdu.dk/u/marco/EMAA/Talks/emaa06-fonseca.pdf)

The read_datasets function is reading datasets of non-dominated point sets? 

The visualisations seem to connect close points from the pareto front

### Hypervolume
[The Hypervolume Indicator: Problems and Algorithms](https://arxiv.org/pdf/2005.00515.pdf)

(This paper includes some visualiations of 3d hypervolumes)

"The
set of all Pareto-optimal solutions (in decision space) is known as the Pareto-optimal set, and the
corresponding images in objective space is known as the Pareto front"

Quality of result dataset is based on:
1. Closeness to pareto front
2. Diversity of the set (more evenly distributed better)
3. The spread

[Youtube example](https://www.youtube.com/watch?v=cR4r1aNPBkQ)
The hypervolume takes the reference point and fills the area until it reaches the pareto- front. The area of the filled area is the hypervolume

### Visualizations for decision support in scenario-based multiobjective optimization
https://www.sciencedirect.com/science/article/pii/S0020025521007155?via%3Dihub